<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <h1 id="active-subspaces-1-finding-important-directions-in-high-dimensions">Active Subspaces 1: Finding Important Directions in High Dimensions</h1> <h2 id="1-motivation">1. Motivation</h2> <p>In science and engineering, models often involve <strong>dozens of variables</strong>‚Äîgeometric parameters, material properties, operating conditions. At first glance, every variable seems important. But experience tells us that <strong>not all directions in parameter space matter equally</strong>.</p> <ul> <li>Example: In fluid dynamics, instead of separately worrying about velocity, length scale, and viscosity, engineers combine them into a single dimensionless group‚Äîthe Reynolds number.</li> <li>This kind of reduction is powerful: a high-dimensional problem hides a <strong>lower-dimensional structure</strong>.</li> </ul> <p><strong>Active Subspaces</strong> is a systematic way to uncover these hidden structures. Instead of guessing which combinations matter, the method discovers ‚Äúimportant directions‚Äù directly from the model.</p> <hr> <h2 id="2-the-core-idea">2. The Core Idea</h2> <p>At its heart, the method assumes that a function can often be approximated as a <strong>ridge function</strong>:</p> \[f(x) \approx g(W^T x),\] <p>where:</p> <ul> <li>$x$ = original high-dimensional input,</li> <li>$W^T x$ = a low-dimensional linear combination of variables,</li> <li>$g$ = a simpler function defined on these few combinations.</li> </ul> <p>üëâ Translation: the model doesn‚Äôt care about each variable separately, but rather about a few <strong>key mixtures</strong>.</p> <p>We won‚Äôt dive into the full mathematics yet‚Äîthat‚Äôs Part 2. For now, keep in mind: <strong>Active Subspaces = finding those mixtures automatically</strong>.</p> <hr> <h2 id="3-a-toy-example">3. A Toy Example</h2> <p>Consider a simple 2D function:</p> \[f(x_1, x_2) = \sin(x_1 + 0.1 x_2).\] <p>At first, it looks like both $x_1$ and $x_2$ are needed.<br> But if you look closer, the function only depends on the <strong>direction $x_1 + 0.1x_2$</strong>. That‚Äôs the <em>important direction</em>.</p> <p><a href="https://colab.research.google.com/github/cocoJ-P/LinearAlgebra-in-MosaicX/blob/main/democode/ActiveSubspace.ipynb" rel="external nofollow noopener" target="_blank"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">X1</span><span class="p">,</span> <span class="n">X2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
<span class="n">F</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sin</span><span class="p">(</span><span class="n">X1</span> <span class="o">+</span> <span class="mf">0.1</span><span class="o">*</span><span class="n">X2</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">contourf</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">F</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="sh">"</span><span class="s">viridis</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">$x_1$</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">$x_2$</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">"</span><span class="s">Contours of $f(x_1, x_2) = sin(x_1 + 0.1 x_2)$</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">colorbar</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">f value</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

</code></pre></div></div> <p>What you‚Äôd see:</p> <p>Contours aligned along diagonal stripes.</p> <p>The model is essentially one-dimensional, even though it lives in 2D.</p> <p>That diagonal is exactly the kind of structure Active Subspaces is built to reveal.</p> <hr> <h2 id="4-takeaways">4. Takeaways</h2> <p>High-dimensional models often collapse to low-dimensional behavior.</p> <p>Active Subspaces provides a <strong>systematic tool</strong> to find the directions where the function changes the most.</p> <p>This is different from PCA: PCA only looks at data variation, while Active Subspaces looks at <strong>function sensitivity</strong>.</p> <p>In <strong>Part 2</strong>, we‚Äôll dive into the method itself: gradients, covariance matrices, and eigenvectors‚Äîthe real machinery behind Active Subspaces.</p> </body></html>